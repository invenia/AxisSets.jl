var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = AxisSets","category":"page"},{"location":"#AxisSets","page":"Home","title":"AxisSets","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [AxisSets]","category":"page"},{"location":"#AxisSets.Pattern","page":"Home","title":"AxisSets.Pattern","text":"Patter\n\nA pattern is just a wrapper around a Tuple{Vararg{Symbol}} which enables searching for matching components and dimension paths in a Dataset. Special symbols :_ and :__ are used as wildcards, similar to * and ** in glob pattern matching.\n\n\n\n\n\n","category":"type"},{"location":"demo/#Demo","page":"Example","title":"Demo","text":"","category":"section"},{"location":"demo/","page":"Example","title":"Example","text":"In this demo, we're going to step through a set of common operations we typically perform when converting a collection of individually fetch features into a simple set of training fetures (X, y) and predict/testing features (X', y').","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"Lets start by loading some packages we'll need.","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"using AxisKeys, AxisSets, DataFrames, Dates, Impute, Random, TimeZones\nusing AxisSets: Dataset, Pattern","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"Now we'll create some arbitary datasets. We're using DataFrames for simplicity, but we could also construct our Dataset from a LibPQ.Result via the Tables interface.","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"# Only gonna lookback 4 days on the same hour and our training data only covers 1 week\ntrain_input_times = DateTime(2021, 1, 1):Hour(1):DateTime(2021, 1, 7);\ntrain_output_times = train_input_times .+ Day(1);\n\n# Predict times are just the next day\npredict_input_times = DateTime(2021, 1, 7):Hour(1):DateTime(2021, 1, 8);\npredict_output_times = predict_input_times .+ Day(1);\n\n# We're gonna say that price, load and temp nodes are different non-overlapping ids\nnode_ids = [:a, :b, :c, :d];\nload_ids = [:p, :q];\ntemp_ids = [:x, :y, :z];\n\n# Lookback lag for prices, we're only applying the lag to prices just to keep things interesting.\nfeature_lags = Day.(-1:-1:-4);\n\nrng = MersenneTwister(1234);\n\n# Some\nmisratios = Dict(\n    :a => 0.1,\n    :b => 0.2,\n    :c => 0.3,\n    :d => 0.4,\n    :p => 0.1,\n    :q => 0.2,\n    :x => 0.1,\n    :y => 0.2,\n    :z => 0.3,\n);\n\n# A modified `rand` which has some probability of producing `missing` values based on\n# the id and some preset factor\nfunction misrand(factor, id)::Union{Missing, Float64}\n    ratio = factor * misratios[id]\n    @assert ratio >= 0.0\n    rand(rng) > ratio || return missing\n    return rand(rng)\nend;\n\ntrain_factor = 0.2;\npredict_factor = 0.1;\n\ndata = (\n    train = (\n        input = (\n            prices = DataFrame(\n                NamedTuple{(:time, :id, :lag, :price)}((t..., misrand(train_factor, t[2])))\n                for t in Iterators.product(train_input_times, node_ids, feature_lags)\n            ),\n            load = DataFrame(\n                NamedTuple{(:time, :id, :load)}((t..., misrand(train_factor, t[2])))\n                for t in Iterators.product(train_input_times, load_ids)\n            ),\n            temp = DataFrame(\n                NamedTuple{(:time, :id, :temperature)}((t..., misrand(train_factor, t[2])))\n                for t in Iterators.product(train_input_times, temp_ids)\n            ),\n        ),\n        output = (\n            prices = DataFrame(\n                NamedTuple{(:time, :id, :price)}((t..., misrand(train_factor, t[2])))\n                for t in Iterators.product(train_output_times, node_ids)\n            ),\n        ),\n    ),\n    predict = (\n        input = (\n            prices = DataFrame(\n                NamedTuple{(:time, :id, :lag, :price)}((t..., misrand(predict_factor, t[2])))\n                for t in Iterators.product(predict_input_times, node_ids, feature_lags)\n            ),\n            load = DataFrame(\n                NamedTuple{(:time, :id, :load)}((t..., misrand(predict_factor, t[2])))\n                for t in Iterators.product(predict_input_times, load_ids)\n            ),\n            temp = DataFrame(\n                NamedTuple{(:time, :id, :temperature)}((t..., misrand(predict_factor, t[2])))\n                for t in Iterators.product(predict_input_times, temp_ids)\n            ),\n        ),\n        output = (\n            prices = DataFrame(\n                NamedTuple{(:time, :id, :price)}((t..., misrand(predict_factor, t[2])))\n                for t in Iterators.product(predict_output_times, node_ids)\n            ),\n        ),\n    ),\n)","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"Okay, so we now have an awkward nested structure of training and predicting inputs and outputs.","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"What are some of the assumption or constraints that must hold throughout our data wrangling and analysis?","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"All the time related columns must maintain consistency with one another (e.g., train_input_times, predict_input_times)\nAll ids must maintain consistency between the train and predict inputs. (e.g., node_id, load_id, temp_id)","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"Lets see if we can perform some common cleanup and transformation on this.","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"components = (\n    k => allowmissing(wrapdims(v, Tables.columnnames(v)[end], Tables.columnnames(v)[1:end-1]...))\n    for (k, v) in pairs(AxisSets.flatten(data))\n);\nconstraints = Pattern[\n    # All train input time keys should match\n    (:train, :input, :_, :time),\n    # All train output time keys should match\n    (:train, :output, :_, :time),\n\n    # All predict input time keys should match\n    (:predict, :input, :_, :time),\n    # All predict output time keys should match\n    (:predict, :output, :_, :time),\n\n    # All ids for each data type should align across\n    (:__, :prices, :id),\n    (:__, :temp, :id),\n    (:__, :load, :id),\n];\nds = Dataset(components...; constraints=constraints)","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"Let's perform some common operations:","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"We often want to filter out ids being consider if they have too many missing values. Let's define a rule for when we want to filter out an id.","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"threshold = 0.1;\nfunction filter_rule(x)\n    r = count(ismissing, x) / length(x)\n    r < threshold\nend;","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"Okay, so lets try just applying this filtering rule to each component of our dataset","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"unique(axiskeys(Impute.filter(filter_rule, v; dims=:id), :id) for (k, v) in ds.data)","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"We can see that doing this results in inconsistent :id keys across our components. Now lets try applying a batched version of that filtering rule across the entire dataset.","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"ds = Impute.filter(filter_rule, ds; dims=:id);\nunique(axiskeys(ds, :id))","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"Notice how our returned Dataset respects the :id constraints we provided above. Another kind of filtering we often do is dropping hours with any missing data after this point.","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"ds = Impute.filter(ds; dims=:time);\nunique(axiskeys(ds, :time))","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"You'll notice that we may have up-to 4 unique :time keys among our 8 components. This is because we only expect keys to align across each :train/predict and input/output combinations as described above.","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"Finally, we should be able to restrict the component KeyedArrays to disallowmissing.","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"# NOTE: I don't love the name of this function, maybe we could just overload `map!`?\nAxisSets.mapset!(disallowmissing, ds)","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"Another common workflow need is to mutate the key values in batches. In this case, we'll say that we need to convert the :time keys to ZonedDateTimes.","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"# Again, I'm open to another names\nAxisSets.rekey!(k -> ZonedDateTime.(k, tz\"UTC\"), ds, :time)","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"Optionally, we could also choose to flatten our inputs/ouputs into 2-d matrices which is what many ML algorithms expect.","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"AxisSets.flatten!(ds, (:id, :lag) => :id)","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"Okay, so now that all of our data manipulation is complete we might want to collapse this back to a named tuple of X and y values to fit the usual ML notation.","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"results = (\n    X = hcat(values(ds(:train, :input, :_))...),\n    y = ds[(:train, :output, :prices)],\n    X̂ = hcat(values(ds(:predict, :input, :_))...),\n    ŷ = ds[(:predict, :output, :prices)],\n)","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"Questions:","category":"page"},{"location":"demo/","page":"Example","title":"Example","text":"Show the before or after?\nShould we construct a new dataset at the end rather than a NamedTuple?","category":"page"}]
}
